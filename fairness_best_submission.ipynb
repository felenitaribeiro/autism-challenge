{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "<table style=\"width:100%; background-color:transparent;\">\n",
    "  <tr style=\"background-color:transparent;\">\n",
    "    <td style=\"background-color:transparent;\">[<img src=\"http://project.inria.fr/saclaycds/files/2017/02/logoUPSayPlusCDS_990.png\" width=\"70%\">](http://www.datascience-paris-saclay.fr)</td>\n",
    "    <td style=\"background-color:transparent;\">[<img src=\"https://paris-saclay-cds.github.io/autism_challenge/images/institut_pasteur_logo.svg\" width=\"30%\">](https://research.pasteur.fr/en/team/group-roberto-toro/)</td>\n",
    "  </tr>\n",
    "</table> \n",
    "</div>\n",
    "\n",
    "<center><h1>Imaging-psychiatry challenge: predicting autism</h1></center>\n",
    "\n",
    "<center><h3>A data challenge on Autism Spectrum Disorder detection</h3></center>\n",
    "<br/>\n",
    "<center>_Roberto Toro (Institut Pasteur), Nicolas Traut (Institut Pasteur), Anita Beggiato (Institut Pasteur), Katja Heuer (Institut Pasteur),<br /> Gael Varoquaux (Inria, Parietal), Alex Gramfort (Inria, Parietal), Balazs Kegl (LAL),<br /> Guillaume Lemaitre (CDS), Alexandre Boucaud (CDS), and Joris van den Bossche (CDS)_</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set up your conda environment\n",
    "\n",
    "Before going to the nitty-gritty, make sure you installed all required packages as in the ami_environment.yml file.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by downloading the data from Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data\n",
    "from problem import get_test_data\n",
    "\n",
    "data_train, labels_train = get_train_data()\n",
    "data_test, labels_test = get_test_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Task 1*\n",
    "\n",
    "Print the number of males and females in the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Gender Data\n",
      "M    900\n",
      "F    227\n",
      "Name: participants_sex, dtype: int64\n",
      "Test Data Gender Data\n",
      "M    20\n",
      "F     3\n",
      "Name: participants_sex, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Gender Data\")\n",
    "print(data_train[\"participants_sex\"].value_counts())\n",
    "\n",
    "print(\"Test Data Gender Data\")\n",
    "print(data_test[\"participants_sex\"].value_counts())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from problem import get_cv\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def evaluation(X, y):\n",
    "    pipe = make_pipeline(FeatureExtractor(), Classifier())\n",
    "    cv = get_cv(X, y)\n",
    "    # cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "    results = cross_validate(pipe, X, y, scoring=['roc_auc', 'accuracy'], cv=cv,\n",
    "                             verbose=1, return_train_score=True,\n",
    "                             n_jobs=2)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluation_predict(X,y):\n",
    "    # Note: in the cross_validate function, they use StratifiedShuffleSplit which allows for resampling\n",
    "    pipe = make_pipeline(FeatureExtractor(), Classifier())\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle = True, random_state=42) \n",
    "    \n",
    "    results = cross_val_predict(pipe, X, y, cv=cv,\n",
    "                             verbose=1, n_jobs=2, method='predict')\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Task 2*\n",
    "Print the proportion of males and females in each fold of the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Training Gender Proportion Female 1 : Male 3.74 & 190:711\n",
      "Fold 1: Test Gender Proportion Female 1 : Male 5.11 & 37:189\n",
      "Fold 2: Training Gender Proportion Female 1 : Male 4.24 & 172:729\n",
      "Fold 2: Test Gender Proportion Female 1 : Male 3.11 & 55:171\n",
      "Fold 3: Training Gender Proportion Female 1 : Male 3.88 & 185:717\n",
      "Fold 3: Test Gender Proportion Female 1 : Male 4.36 & 42:183\n",
      "Fold 4: Training Gender Proportion Female 1 : Male 3.96 & 182:720\n",
      "Fold 4: Test Gender Proportion Female 1 : Male 4.0 & 45:180\n",
      "Fold 5: Training Gender Proportion Female 1 : Male 4.04 & 179:723\n",
      "Fold 5: Test Gender Proportion Female 1 : Male 3.69 & 48:177\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=np.ModuleDeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*`np.*` is a deprecated alias.*\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) \n",
    "data_train_sex = np.array(data_train['participants_sex'])\n",
    "fold_number = 1\n",
    "for train_index, test_index in cv.split(data_train,labels_train):\n",
    "    train = data_train_sex[train_index]\n",
    "    test = data_train_sex[test_index]\n",
    "\n",
    "    train_male_count = np.count_nonzero(train == 'M')\n",
    "    train_female_count = np.count_nonzero(train == 'F')\n",
    "\n",
    "    test_male_count = np.count_nonzero(test == 'M')\n",
    "    test_female_count = np.count_nonzero(test == 'F')\n",
    "\n",
    "    print(\"Fold \", fold_number, \": Training Gender Proportion \", \"Female 1 : Male \", round(train_male_count/train_female_count, 2), \" & \", train_female_count, \":\", train_male_count, sep = \"\")\n",
    "    print(\"Fold \", fold_number, \": Test Gender Proportion \", \"Female 1 : Male \", round(test_male_count/test_female_count, 2), \" & \", test_female_count, \":\", test_male_count, sep = \"\")\n",
    "    fold_number += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the submission"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each submission defines a `FeatureExtractor` and a `Classifier`. It relies on:\n",
    "\n",
    "* the file `submissions/<submission_name>/feature_extractor.py` corresponding to the feature extractor;\n",
    "* the file `submission/<submission_name>/classifier.py` corresponding to the classifier.\n",
    "\n",
    "In the cells below, you can change the name of the `<submission_name>` to load on the desired solution and later run it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load submissions/starting_kit/feature_extractor.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load submissions/starting_kit/classifier.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the data from https://zenodo.org/record/3625740/files/power_2011.zip ...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=np.ModuleDeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*`np.*` is a deprecated alias.*\")\n",
    "\n",
    "from submissions.nguigui_original.classifier import Classifier\n",
    "from submissions.nguigui_original.feature_extractor import FeatureExtractor\n",
    "\n",
    "# Make sure you download the functional data, if it is not already stored on your drive\n",
    "from download_data import fetch_fmri_time_series\n",
    "fetch_fmri_time_series(atlas='all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structural MRI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score ROC-AUC: 1.000 +- 0.000\n",
      "Validation score ROC-AUC: 0.735 +- 0.022 \n",
      "\n",
      "Training score accuracy: 1.000 +- 0.000\n",
      "Validation score accuracy: 0.670 +- 0.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   8 out of   8 | elapsed:  8.7min finished\n"
     ]
    }
   ],
   "source": [
    "results = evaluation(data_train, labels_train)\n",
    "\n",
    "print(\"Training score ROC-AUC: {:.3f} +- {:.3f}\".format(\n",
    "   np.mean(results['train_roc_auc']), np.std(results['train_roc_auc'])))\n",
    "print(\"Validation score ROC-AUC: {:.3f} +- {:.3f} \\n\".format(\n",
    "   np.mean(results['test_roc_auc']), np.std(results['test_roc_auc'])))\n",
    "\n",
    "print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(\n",
    "   np.mean(results['train_accuracy']), np.std(results['train_accuracy'])))\n",
    "print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(\n",
    "   np.mean(results['test_accuracy']), np.std(results['test_accuracy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\".*`np.*` is a deprecated alias.*\")\n",
    "predictions = evaluation_predict(data_train,labels_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Task 3*\n",
    "\n",
    "Complete this function to return model's accuracy for male and female samples seperately for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_protectedGroups(predictions, cv_split, data, file_name):\n",
    "  warnings.filterwarnings(\"ignore\", message=\".*`np.*` is a deprecated alias.*\")\n",
    "\n",
    "  fold_pred = [predictions[test] for train, test in cv.split(data_train,labels_train)]\n",
    "  fold_labels = [np.array(labels_train)[test] for train, test in cv.split(data_train,labels_train)]\n",
    "\n",
    "  data_train_sex = np.array(data_train['participants_sex'])\n",
    "  #print(data_train_sex)\n",
    "  i=0\n",
    "  f = open(file_name+\".txt\", \"w\")\n",
    "  for train_index, test_index in cv_split:\n",
    "    male_accuracy = 0\n",
    "    male_total = 0\n",
    "    female_accuracy = 0\n",
    "    female_total = 0\n",
    "    train = data_train_sex[train_index]\n",
    "    test = data_train_sex[test_index]\n",
    "    #print(fold_pred[i])\n",
    "    #print(fold_labels[i]) \n",
    "    #index = 0\n",
    "    for index in range(len(fold_pred[i])): \n",
    "        f.write(str(fold_pred[i][index]))\n",
    "        f.write(\",\")\n",
    "        f.write(str(fold_labels[i][index]))\n",
    "        f.write(\"\\n\")\n",
    "        if test[index] == 'M':\n",
    "            male_total += 1\n",
    "            # print(index, \"M\", test[index], fold_pred[i][index], fold_labels[i][index])\n",
    "            if round(fold_pred[i][index]) == fold_labels[i][index]:\n",
    "              male_accuracy += 1\n",
    "        else:\n",
    "            #print(index, \"F\", test[index])\n",
    "            female_total += 1\n",
    "            if round(fold_pred[i][index]) == fold_labels[i][index]:\n",
    "              female_accuracy += 1\n",
    "    #print(\"Train: \", train)\n",
    "    #print(\"Test: \", test)\n",
    "    #print(\"Fold Pred\", )\n",
    "    #print(\"Test Index\", test_index)\n",
    "    i+=1\n",
    "    print(\"Male: \", male_accuracy, \" out of \", male_total,\", \", round(male_accuracy/male_total*100, 2), \"%. Female: \", female_accuracy, \" out of \", female_total, \", \", round(female_accuracy/female_total*100, 2), \"%. Total participants: \", female_total + male_total, sep=\"\")\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male: 130 out of 189, 68.78%. Female: 22 out of 37, 59.46%. Total participants: 226\n",
      "Male: 115 out of 171, 67.25%. Female: 42 out of 55, 76.36%. Total participants: 226\n",
      "Male: 118 out of 183, 64.48%. Female: 36 out of 42, 85.71%. Total participants: 225\n",
      "Male: 119 out of 180, 66.11%. Female: 33 out of 45, 73.33%. Total participants: 225\n",
      "Male: 120 out of 177, 67.8%. Female: 36 out of 48, 75.0%. Total participants: 225\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle = True, random_state=42) \n",
    "cv_split = cv.split(data_train, labels_train)\n",
    "\n",
    "\n",
    "accuracy_protectedGroups(predictions, cv_split, data_train, \"mk_original\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "autism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a04a11fdfc4d332fcd2404c1f138153c6bff2fb193e412588c027a4802effbc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
